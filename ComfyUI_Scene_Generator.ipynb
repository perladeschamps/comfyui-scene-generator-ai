{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d4bea3",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ“š ComfyUIÂ SceneÂ GeneratorÂ forÂ Books  \n",
    "Generate highâ€‘quality image sequences from a reference picture using **StableÂ DiffusionÂ XL (SDXL)** on **ComfyUI**, all without ever leaving this GoogleÂ Colab notebook.\n",
    "\n",
    "---\n",
    "\n",
    "### What youâ€™ll get\n",
    "| | |\n",
    "|---|---|\n",
    "|ğŸ“· **Upload an image** to use as the starting frame|ğŸ¨ **Style box** â€“ describe the mood (e.g. â€œdark animeâ€, â€œvintage illustrationâ€, etc.)|\n",
    "|ğŸ”¢ **Images slider** â€“ choose **1Â â€“Â 100** renders per scene|ğŸ” **Softâ€‘variation toggle** to introduce gentle pose / lighting / background changes|\n",
    "|ğŸ‘ï¸ **Instant preview** of every frame inside the notebook|âœ… **ApproveÂ &Â save** only the frames you like â†’ autoâ€‘copies to GoogleÂ Drive|\n",
    "\n",
    "> **Tip:** The notebook also installs the full ComfyUI web interface â€“ open it in another browser tab if you want nodeâ€‘level control.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25531d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title ğŸ”§Â Install ComfyUI & dependenciesÂ â†˜ï¸ (takes 2â€‘3Â min)\n",
    "!pip -q install --upgrade diffusers[torch] transformers accelerate safetensors einops xformers ipywidgets nbformat\n",
    "!git clone --depth 1 https://github.com/comfyanonymous/ComfyUI.git || echo \"ComfyUI already cloned\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986d1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title ğŸ”—Â Mount GoogleÂ Drive (for saving approved frames)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/ComfyUI_Generated'\n",
    "import os, pathlib\n",
    "pathlib.Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Images you approve will be copied to: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898341b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title â–¶ï¸Â (Optional) Launch the ComfyUI web interface\n",
    "# Skips if already running. Access on  https://<colabâ€‘host>:8188  (use Colab â†— menu â†’ â€˜Previewâ€™)\n",
    "import subprocess, os, signal, time, textwrap, json, pathlib, random, io, base64, types, sys, math, functools\n",
    "if not os.path.exists('/content/ComfyUI'):\n",
    "    print(\"ComfyUI folder missing â€“Â reâ€‘run install cell\")\n",
    "else:\n",
    "    proc = subprocess.Popen(['python', 'main.py', '--listen', '0.0.0.0', '--port', '8188', '--disable-auto-launch'], cwd='/content/ComfyUI')\n",
    "    time.sleep(5)\n",
    "    print(\"ComfyUI server started on http://localhost:8188 (use 'Open in new tab' from Colab)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title ğŸš€Â Load SDXL Img2ImgÂ pipeline (â‰ˆÂ 1Â min on first run)\n",
    "import torch, gc, contextlib, warnings\n",
    "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    variant=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    ").to(\"cuda\")\n",
    "pipe.enable_xformers_memory_efficient_attention()\n",
    "print(\"âœ” SDXL pipeline ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title ğŸ›ï¸Â InteractiveÂ Generator\n",
    "import ipywidgets as wd, io, random, math\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "uploader       = wd.FileUpload(accept='image/*', multiple=False, description='UploadÂ â†—')\n",
    "style_txt      = wd.Text(value='', placeholder='e.g. dark anime', description='Style:')\n",
    "num_slider     = wd.IntSlider(value=10, min=1, max=100, step=1, description='Images:', continuous_update=False)\n",
    "variation_ck   = wd.Checkbox(value=True, description='SoftÂ variation')\n",
    "generate_btn   = wd.Button(description='Generate', button_style='success')\n",
    "approve_btn    = wd.Button(description='SaveÂ selected', button_style='primary')\n",
    "preview_out    = wd.Output(layout={'border': '1px solid #ddd','padding':'4px'})\n",
    "select_multi   = wd.SelectMultiple(options=[], description='Pick â¬‡')\n",
    "\n",
    "last_images = []  #Â holds PIL images in current batch\n",
    "\n",
    "def _pil_to_bytes(img):\n",
    "    bio = io.BytesIO()\n",
    "    img.save(bio, format='PNG')\n",
    "    return bio.getvalue()\n",
    "\n",
    "def on_generate(b):\n",
    "    with preview_out:\n",
    "        clear_output(wait=True)\n",
    "        if len(uploader.value) == 0:\n",
    "            print(\"â¬†ï¸Â Please upload a reference image first.\"); return\n",
    "        #Â prepare init img\n",
    "        ref_bytes = next(iter(uploader.value.values()))['content']\n",
    "        init_img = Image.open(io.BytesIO(ref_bytes)).convert('RGB')\n",
    "        init_img = init_img.resize((1024, 1024))\n",
    "        global last_images\n",
    "        last_images = []\n",
    "        options = []\n",
    "        base_prompt = style_txt.value.strip() or \"illustration\"\n",
    "        print(\"â³ Generatingâ€¦\")\n",
    "        for i in range(num_slider.value):\n",
    "            prompt = base_prompt\n",
    "            if variation_ck.value:\n",
    "                prompt += \", \" + random.choice([\"alternate angle\", \"dynamic lighting\", \"subtle pose shift\", \"different background\"])\n",
    "            image = pipe(\n",
    "                prompt            = prompt,\n",
    "                image             = init_img,\n",
    "                strength          = 0.7,\n",
    "                guidance_scale    = 7.0,\n",
    "                num_inference_steps=30,\n",
    "            ).images[0]\n",
    "            last_images.append(image)\n",
    "            options.append((f\"ImageÂ {i+1}\", i))\n",
    "            #Â display thumbnail grid\n",
    "        thumbs = [wd.Image(value=_pil_to_bytes(im), format='png', width=180) for im in last_images]\n",
    "        rows = [wd.HBox(thumbs[i:i+4]) for i in range(0, len(thumbs), 4)]\n",
    "        display(wd.VBox(rows))\n",
    "        select_multi.options = options\n",
    "        print(\"âœ” Generation complete â€“ select frames to save\")\n",
    "\n",
    "def on_save(b):\n",
    "    if not select_multi.value:\n",
    "        with preview_out: print(\"ğŸ””Â No frames selected.\")\n",
    "        return\n",
    "    count = 0\n",
    "    for idx in select_multi.value:\n",
    "        fname = f\"{OUTPUT_DIR}/scene_{idx:03d}.png\"\n",
    "        last_images[idx].save(fname)\n",
    "        count += 1\n",
    "    with preview_out:\n",
    "        print(f\"âœ…Â Saved {count} images â†’ {OUTPUT_DIR}\")\n",
    "\n",
    "generate_btn.on_click(on_generate)\n",
    "approve_btn.on_click(on_save)\n",
    "\n",
    "ui = wd.VBox([wd.HBox([uploader, style_txt]), num_slider, variation_ck,\n",
    "              wd.HBox([generate_btn, approve_btn]), select_multi, preview_out])\n",
    "display(ui)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
